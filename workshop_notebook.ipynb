{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center><font size=5>SETI Breakthrough Listen - E.T. Signal Search üëΩ</font></center>**\n",
    "<center><font size=4>By Ben Shaver and Coral Hayoun</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Abstract\n",
    "\n",
    "##### **\"Are we alone in the Universe?\"**\n",
    "\n",
    "It's one of the most profound human questions.\n",
    "As technology improves, we're finding new and more powerful ways to seek for answers.\n",
    "\n",
    "The Breakthrough Listen team at Berkeley University, scans signals from millions of stars in the universe using world's most powerful telescopes, trying\n",
    "to answer this question. Unfortunately, finding extraterrestial signals is not that easy - by the time, humans have built enormous numbers of radio devices that can be detected as signals as well and distract researchers.\n",
    "\n",
    "In order to separate outer space signals from RFI (radio frequency interference), The Breakthrough Listen team are using two different filters:\n",
    "1. They intersperses scans of target stars that apprears in more than one regions of the sky - because these scans probably aren't coming from the direction of the target star.\n",
    "2. They discards signals that don't change their frequency - because it means that they are probably nearby the telescope.\n",
    "\n",
    "These two methods are quite effective, but they can be improved. The process today misses interesting signals. particularly those with complex time or frequency structure, and those in regions of the spectrum with lots of interference.\n",
    "\n",
    "<br></br>\n",
    "In this competition, we will use our machine learning skills to accurately identify the presence of simulated extraterrestial signals in these scans.\n",
    "\n",
    "Because there are no confirmed examples of alien signals to use to train machine learning algorithms, the team included some simulated signals (that they call ‚Äú**needles**‚Äù) in the haystack of data from the telescopes. They have identified some of the hidden needles so that we can train our model to find more.\n",
    "\n",
    "<br></br>\n",
    "<center><img src=\"https://i.pinimg.com/originals/89/e6/91/89e6912b1225c43ed18b7c2b31069f77.jpg\" width=\"600\"></center>\n",
    "\n",
    "(from [SETI Breakthrough Listen - Kaggle competition](https://www.kaggle.com/competitions/seti-breakthrough-listen)) <br></br>\n",
    "\n",
    "----\n",
    "\n",
    "##### **Table of Contents**\n",
    "- <a href='#1'>1. Initial Settings | ‚öôÔ∏è</a>\n",
    "- <a href='#2'>2. Exploratory Data Analysis | üî¶</a>\n",
    "  - <a href='#2_1'>2.1. Data Loading</a>\n",
    "  - <a href='#2_2'>2.2. Data Visualizing</a>\n",
    "  - <a href='#2_3'>2.3. Data Statistics</a>\n",
    "    - <a href='#2_3_1'>2.3.1 Needles Distribution</a>\n",
    "    - <a href='#2_3_2'>2.3.2 Basic Statistical Features</a>\n",
    "  - <a href='#2_4'>2.4. Noise Analyzing</a>\n",
    "    - <a href='#2_4_1'>2.4.1 Gaussian Noise</a>\n",
    "    - <a href='#2_4_2'>2.4.2 Frequency Domain Analysis</a>\n",
    "    - <a href='#2_4_3'>2.4.3 Wavelet Transform Analysis</a>\n",
    "  - <a href='#2_5'>2.5. Clustering</a>\n",
    "    - <a href='#2_5_1'>2.5.1 Data Respresentation</a>\n",
    "      - <a href='#2_5_1_1'>2.5.1.1. Vertical Detail Coefficients (cV)</a>\n",
    "      - <a href='#2_5_1_2'>2.5.1.2. SIFT</a>\n",
    "      - <a href='#2_5_1_3'>2.5.1.3. HOG</a>\n",
    "      - <a href='#2_5_1_4'>2.5.1.4. LBP</a>\n",
    "    - <a href='#2_5_2'>2.5.2 Dimensionality Reduction - PCA</a>\n",
    "    - <a href='#2_5_3'>2.5.3 K-means</a>\n",
    "- <a href='#3'>3. Data Preprocessing | üçΩÔ∏è</a>\n",
    "  - <a href='#3_1'>3.1. Data Cleaning</a>\n",
    "  - <a href='#3_2'>3.2. Data Augmentation</a>\n",
    "  - <a href='#3_3'>2.3. Data Adjustments</a>\n",
    "- <a href='#4'>4. Data Splitting | üî™</a>\n",
    "- <a href='#5'>5. Train A Simple Model | üêá</a>\n",
    "  - <a href='#5_1'>5.1. Model Building</a>\n",
    "  - <a href='#5_2'>5.2. Preprocessing Pipeline</a>\n",
    "  - <a href='#5_3'>5.3. Training Function</a>\n",
    "  - <a href='#5_4'>5.4. Predictions</a>\n",
    "  - <a href='#5_5'>5.5. Final Results</a>\n",
    "- <a href='#6'>6. Train An Improved Simple Model | ü¶ç</a>\n",
    "- <a href='#7'>7. Train A Deep Learning Model | ü§ñ</a>\n",
    "  - <a href='#7_1'>7.1. Model Building</a>\n",
    "  - <a href='#7_2'>7.2. Preprocessing Pipeline</a>\n",
    "  - <a href='#7_3'>7.3. Training Function</a>\n",
    "  - <a href='#7_4'>7.4. Predictions</a>\n",
    "  - <a href='#7_5'>7.5. Final Results</a>\n",
    "- <a href='#8'>8. Conclusions | üí°</a>\n",
    "\n",
    "\n",
    "  ----\n",
    "\n",
    "# <a id='1'>1. Initial Settings | ‚öôÔ∏è</a>\n",
    "\n",
    "##### 1. Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q pywavelets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For operating system and file system\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# For basic functionallity\n",
    "import math\n",
    "\n",
    "# For data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "\n",
    "# For Computer Vision Library\n",
    "import cv2\n",
    "from skimage import exposure\n",
    "from skimage.feature import hog\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "# For Deep Learning\n",
    "import tensorflow as tf\n",
    "import efficientnet.tfkeras as efficientnet\n",
    "from tensorflow.keras import layers\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "# For Machine Learning\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# For data manipulation\n",
    "from skimage.transform import resize\n",
    "from skimage.restoration import estimate_sigma\n",
    "\n",
    "# For data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "# For model persistence\n",
    "import joblib\n",
    "\n",
    "# For warning filtering\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes it can be necessary to re-run this command for plots to show automatically\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Libraries Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('np version:',np.__version__)\n",
    "print('pd version:',pd.__version__)\n",
    "print('tf version:',tf.__version__)\n",
    "print('sklearn version:',sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # ------------------------------------#\n",
    "    # Basic\n",
    "    # ------------------------------------#\n",
    "    debug = True\n",
    "    runOnKaggle = False\n",
    "    epochs = 1\n",
    "    train_batch_size = 64\n",
    "    validation_batch_size = 20\n",
    "    data_augmentation_size = 5000\n",
    "    test_batch_size = 64\n",
    "    seed = 42\n",
    "    k_fold = 4\n",
    "\n",
    "    # ------------------------------------#\n",
    "    # Paths\n",
    "    # ------------------------------------#\n",
    "    if runOnKaggle:\n",
    "        base_folder_path = '/kaggle/input/seti-breakthrough-listen'\n",
    "        tmp_storage_path = '/kaggle/tmp'\n",
    "        workdir_folder_path = '/kaggle/working'\n",
    "        logging_file = '/kaggle/logging.txt'\n",
    "    else:\n",
    "        base_folder_path = os.path.abspath('../../../Downloads/SETI')\n",
    "        tmp_storage_path = 'tmp'\n",
    "        workdir_folder_path = 'working'\n",
    "        logging_file = 'logging.txt'\n",
    "\n",
    "    train_folder_path = f'{base_folder_path}/train'\n",
    "    test_folder_path = f'{base_folder_path}/train'\n",
    "\n",
    "# ------------------------------------#\n",
    "# On Debug\n",
    "# ------------------------------------#\n",
    "if CFG.debug:\n",
    "    CFG.epochs = 1\n",
    "    CFG.train_batch_size = 50\n",
    "    CFG.validation_batch_size = 25\n",
    "    CFG.test_batch_size = 50\n",
    "    CFG.data_augmentation_size = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Utils Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batched_data (data, batch_size, index):\n",
    "    return data[index * batch_size : (index + 1) * batch_size]\n",
    "\n",
    "def split_data(data, k):\n",
    "    np.random.shuffle(data)\n",
    "    return np.array_split(data, k)\n",
    "\n",
    "def plot_cadence_snippet(cadence_snippet, figsize=(8, 5)):\n",
    "  figure = plt.figure(figsize=figsize)\n",
    "  \n",
    "  for i in range(6):\n",
    "    data = cadence_snippet[i]\n",
    "    channel_text = 'on' if i % 2 == 0 else 'off'\n",
    "    channel_box = dict(facecolor='white', edgecolor='none', boxstyle='square,pad=0.3')\n",
    "    \n",
    "    plt.subplot(6, 1, i + 1)\n",
    "    plt.imshow(data.astype('float16'), aspect='auto', cmap='gray')\n",
    "    plt.text(10, 90, channel_text, color='black', fontsize=8, va='center', ha='center',bbox=channel_box)\n",
    "\n",
    "  figure.text(0.5, 0.04, 'Frequency', ha='center', fontsize=8)\n",
    "  figure.text(0.04, 0.5, 'Time', va='center', rotation='vertical', fontsize=8)\n",
    "  plt.show()\n",
    "\n",
    "def plot_cadence_snippet_by_axes(cadence_snippet, axes):\n",
    "    for i in range(6):\n",
    "        channel_text = 'on' if i % 2 == 0 else 'off'\n",
    "        channel_box = dict(facecolor='white', edgecolor='none', boxstyle='square,pad=0.3')\n",
    "        \n",
    "        ax = axes[i]\n",
    "        ax.imshow(cadence_snippet[i].astype('float16'), aspect='auto', cmap='gray') \n",
    "        ax.text(10, 90, channel_text, color='black', fontsize=8, va='center', ha='center', bbox=channel_box)\n",
    "        ax.axis('off') \n",
    "\n",
    "def plot_multiple_cadence_snippets(cadences_snippet, figsize=(15, 10)):\n",
    "    rows_number = (len(cadences_snippet) + 2) // 3 \n",
    "\n",
    "    figure = plt.figure(figsize=figsize)\n",
    "    grid = figure.add_gridspec(rows_number * 6 + (rows_number - 1), 3 * 6 + 2) \n",
    "\n",
    "    for index, cadence_snippet in enumerate(cadences_snippet):\n",
    "        row_start = (index // 3) * 7  # 6 rows for plots + 1 row for margin\n",
    "        column_start = (index % 3) * 7   # 6 columns for plots + 1 column for margin\n",
    "        \n",
    "        axes = [figure.add_subplot(grid[row_start + i, column_start:column_start + 6]) for i in range(6)]\n",
    "        plot_cadence_snippet_by_axes(cadence_snippet, axes)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_on_channels_cadence_snippet(cadence_snippet):\n",
    "  figure = plt.figure(figsize=(8, 4))\n",
    "  \n",
    "  for i in range(3):\n",
    "    plt.subplot(6, 1, i + 1)\n",
    "    plt.imshow(cadence_snippet[i], aspect='auto')\n",
    "\n",
    "  figure.text(0.5, 0.04, 'Frequency', ha='center', fontsize=8)\n",
    "  figure.text(0.04, 0.5, 'Time', va='center', rotation='vertical', fontsize=8)\n",
    "  plt.show()\n",
    "\n",
    "def plot_merged_cadence_snippet(file, title = None):\n",
    "  plt.figure(figsize=(8, 5))\n",
    "\n",
    "  if title is not None: \n",
    "    plt.title(title) \n",
    "    \n",
    "  plt.imshow(file, aspect='auto')\n",
    "\n",
    "def get_samples_id(df, target_0_amount, target_1_amount):\n",
    "    id_target_0 = df[df['target'] == 0].head(target_0_amount)['id'].tolist()\n",
    "    id_target_1 = df[df['target'] == 1].head(target_1_amount)['id'].tolist()\n",
    "    return id_target_0 + id_target_1\n",
    "\n",
    "def get_samples_by_threshold(df, feature, low_threshold, high_threshold):\n",
    "    random_state = None\n",
    "    low_threshold = np.percentile(df[feature], low_threshold)\n",
    "    high_threshold = np.percentile(df[feature], high_threshold)\n",
    "    median_threshold = np.median(df[feature])\n",
    "    median_low_threshold = median_threshold - 0.1 * median_threshold\n",
    "    median_high_threshold = median_threshold + 0.1 * median_threshold\n",
    "\n",
    "    lowest = shuffle(df[df[feature] < low_threshold], random_state=random_state)\n",
    "    highest = shuffle(df[df[feature] > high_threshold], random_state=random_state)\n",
    "    median = shuffle(df[(df[feature] >= median_low_threshold) & (df[feature] <= median_high_threshold)], random_state=random_state)\n",
    "\n",
    "    return lowest, median, highest\n",
    "\n",
    "def write_predictions_to_file(prediction_data, testing_set_labels, file_name):\n",
    "  results = testing_set_labels.assign(target=prediction_data)\n",
    "  selected_column = ['id', 'target']\n",
    "  final_results = results[selected_column]\n",
    "  final_results.to_csv(file_name, index=False)\n",
    "\n",
    "def get_batch_number(index, batch_size):\n",
    "  return math.floor(index / batch_size)\n",
    "\n",
    "def get_index_in_batch(index, batch_size):\n",
    "  return index - (get_batch_number(index, batch_size) * batch_size)\n",
    "\n",
    "def get_data_set_sample(data_set, n, positive_ratio):\n",
    "    positive_values_samples = min(math.floor(n * positive_ratio),len(data_set[data_set.target == 1]))\n",
    "    positive_samples = data_set[data_set.target == 1].sample(n=positive_values_samples, random_state = CFG.seed).reset_index(drop=True)\n",
    "    complementary_data_set_samples = data_set[data_set.target == 0].sample(n - positive_values_samples, random_state = CFG.seed).reset_index(drop=True)\n",
    "\n",
    "    return pd.concat([positive_samples, complementary_data_set_samples]).sample(frac = 1).reset_index(drop=True)\n",
    "\n",
    "def log(message, shouldPrint=False):\n",
    "  if shouldPrint:\n",
    "    print(message)\n",
    "  logging.info(message)\n",
    "\n",
    "def save_model(model, name):\n",
    "  joblib.dump(model, f'{CFG.workdir_folder_path}/{name}.pkl')\n",
    "  \n",
    "def load_model(name):\n",
    "  return joblib.load(f'{CFG.workdir_folder_path}/{name}.pkl')\n",
    "\n",
    "def get_duration(start_time):\n",
    "  return (time.time() - start_time) / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Initial Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tmp Directory\n",
    "if not os.path.exists(CFG.tmp_storage_path):\n",
    "    os.makedirs(CFG.tmp_storage_path)\n",
    "\n",
    "# Create working Directory\n",
    "if not os.path.exists(CFG.workdir_folder_path):\n",
    "    os.makedirs(CFG.workdir_folder_path)\n",
    "    \n",
    "# Create logging file\n",
    "if not os.path.exists(CFG.logging_file):\n",
    "    with open(CFG.logging_file, 'w'):\n",
    "        pass\n",
    "\n",
    "# Setup logger\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  \n",
    "    format='%(asctime)s - %(message)s',  \n",
    "    filename=CFG.logging_file,  \n",
    "    filemode='a'  \n",
    "  )\n",
    "\n",
    "# Remove unnecessary warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# <a id='2'>2. Exploratory Data Analysis | üî¶</a>\n",
    "\n",
    "\n",
    "With our libraries and configurations set up, we can begin the exploratory data analysis (or EDA).\n",
    "\n",
    "The **goal of EDA** is to understand the data underlying structure and patterns, identify important variables, detect outliers and anomalies and formulate hypotheses for further investigation. \n",
    "\n",
    "This process includes examining the distribution of the data, identifying patterns and trends, applying dimensionality reduction and clustering techniques, and visualizing the data to gain insights.\n",
    "\n",
    "### <a id='2_1'>2.1. Data Loading</a>\n",
    "\n",
    "Even though our task sounds like a *signal* detection problem, we are actually provided with radio spectrograms *images* - a visual representation of the spectrum frequencies of a signal as it varies with time. <br></br>\n",
    "Our full dataset contains:\n",
    "- a `train_labels.csv` file, which has our labels indicating the presence of an alien signal (referred to as needles) for each of the spectograms\n",
    "- `train` folder contains `.npy` float16 files with the spectrograms stored as arrays\n",
    "- Similarly, `test` folder also contains `.npy` float16 files with the test spectrograms stored as arrays <br></br>\n",
    "\n",
    "Because the given testing set is unlabeled, it will be hard to work with it - when we will train our model and make predictions, we will get by Kaggle the accuracy percentages of the predictions only, without the ability to detect the model mistakes or use some more subtle measures. Therefore, we will split our labeled training set using `train_test_split` method into two - 80% of it will keep being our training set, and 20% will become our labeled testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_labels = pd.read_csv(f'{CFG.base_folder_path}/train_labels.csv')\n",
    "\n",
    "if CFG.debug:\n",
    "    samples_amount = 2000\n",
    "    positive_samples_ratio = 0.3\n",
    "    training_set_labels = get_data_set_sample(training_set_labels, samples_amount, positive_samples_ratio)\n",
    "\n",
    "training_set, testing_set = train_test_split(training_set_labels, test_size=0.2, random_state=CFG.seed)\n",
    "\n",
    "# Keep the splitted labels into train and test csv files\n",
    "training_set.to_csv('training_set_labels.csv', index=False)\n",
    "testing_set.to_csv('testing_set_labels.csv', index=False)\n",
    "\n",
    "training_set_labels.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have a total of 60,000 data samples, which means we have 48,000 training set samples and 12,000 testing set samples.<br></br>\n",
    "As we can see, each data sample has an id and stored as a `.npy` file with the path of 'train/{image_id_prefix}/{image_id}.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_path(image_id, folder_path):\n",
    "  return '{}\\{}\\{}.npy'.format(folder_path, image_id[0], image_id)\n",
    "\n",
    "training_set['file_path'] = training_set['id'].apply(lambda id: get_file_path(image_id=id, folder_path=CFG.train_folder_path))\n",
    "testing_set['file_path'] = testing_set['id'].apply(lambda id: get_file_path(image_id=id, folder_path=CFG.test_folder_path))\n",
    "\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After understanding the way our data being stored, we should make sure that our stored data is valid and consistent:\n",
    "- Each record in the csv files should actually has a valid (not nullish) id and label\n",
    "- There are no missing files, which means all the labeled records in the csv files actually has a matched existing file\n",
    "- There are no extra files, which means each existing file actually has a labeled record in our csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_columns = ['id', 'target']\n",
    "cleaned_training_set_labels = training_set_labels.dropna(subset=required_columns)\n",
    "\n",
    "if cleaned_training_set_labels.shape[0] < training_set_labels.shape[0]:\n",
    "    print('Some records has invalid values')\n",
    "else:\n",
    "    print('All records are valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_ids = set(training_set_labels['id'].astype(str))\n",
    "file_ids = set()\n",
    "\n",
    "for root, dirs, files in os.walk(CFG.train_folder_path):\n",
    "    for file_name in files:\n",
    "        # Remove file extension\n",
    "        file_id = os.path.splitext(file_name)[0]\n",
    "        file_ids.add(file_id)\n",
    "\n",
    "missing_files = csv_ids - file_ids\n",
    "extra_files = file_ids - csv_ids\n",
    "\n",
    "if missing_files:\n",
    "    print(f'Files referenced in CSV but missing in train directory: {missing_files}')\n",
    "else:\n",
    "    print('All files referenced in CSV are present in the train directory.')\n",
    "\n",
    "if extra_files:\n",
    "    print(f'Files in train directory but not referenced in CSV: {extra_files}')\n",
    "else:\n",
    "    print('All files in the train directory are referenced in the CSV.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Looks like our stored dataset is consistent and valid to use, now we can delve into its real exploration:\n",
    "\n",
    "### <a id='2_2'>2.2. Data Visualizing</a>\n",
    "\n",
    "Every training set sample is called **cadence snippet**, which looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cadence_snippet = np.load(get_file_path('00776881dd80050', CFG.train_folder_path))\n",
    "print(f'My shape is: {cadence_snippet.shape}')\n",
    "plot_cadence_snippet(cadence_snippet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break this **cadence snippet** down:\n",
    "\n",
    "**Firstly**, the individual plots signify a **cadence**, and the combination of the 6 plots is called a **cadence snippet**\n",
    "\n",
    "**Secondly**, as we can see, the spectrogram has a shape of `(6, 273, 256)` - which stands for a represantation of 6 spectrograms in 2D.\n",
    "The reason for the 6 spectrograms, as we already mentioned in the Abstract section, is that in order to deal with human-generated signals (like radion stations or wifi routers), Breakthrough Listen team are looking for **signals that appear to be coming from particular positions on the sky**.\n",
    "\n",
    "Typically they do this by alternating observations of a primary target star with observations of three nearby stars:\n",
    "- 5 minutes on star ‚ÄúA‚Äù || *on-channel*\n",
    "- then 5 minutes on star ‚ÄúB‚Äù || *off-channel*\n",
    "- then back to star ‚ÄúA‚Äù for 5 minutes || *on-channel*\n",
    "- then ‚ÄúC‚Äù || *off-channel*\n",
    "- then back to ‚ÄúA‚Äù || *on-channel*\n",
    "- then finishing with 5 minutes on star ‚ÄúD‚Äù || *off-channel*\n",
    "\n",
    "One set of six observations (ABACAD) is referred to as our **cadence snippet**.\n",
    "\n",
    "**Thirdly**, The curves we see in the signal's lines, are because the relative motion of the Earth and the star imparts a `Doppler drift`, causing the frequency to change over time. \n",
    "\n",
    "\n",
    "After understanding what cadence snippet is, let's take a look on some more cadence snippets in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Here is a non-alien signals example:')\n",
    "plot_cadence_snippet(np.load(get_file_path('0000799a2b2c42d', CFG.train_folder_path)))\n",
    "\n",
    "print('\\nHere is an easy alien signals example:')\n",
    "plot_cadence_snippet(np.load(get_file_path('d618b77bb0909c2', CFG.train_folder_path)))\n",
    "\n",
    "print('\\nHere is a hard alien signals example:')\n",
    "plot_cadence_snippet(np.load(get_file_path('fffbb1c9c3d6c31', CFG.train_folder_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we came across with our **1st challange: hidden needles**. As we can see, some of these needles should be easy to detect, but others are hidden in noisy regions of the spectrum and will be harder. \n",
    "\n",
    "\n",
    "<div style=\"border: 0.5px solid; padding: 10px; background-color: #FFFACD; border-radius: 5px; color: #000; font-size:14px; line-height: 1.7em; display: flex; flex-direction: row;\">\n",
    "  <div style=\"width: 24px\">üí°</div> \n",
    "  <div style=\"display: flex; flex-direction: column\"> \n",
    "  <div style=\"font-weight:500\">How useful are the off-channels? </div>\n",
    "  <div>\n",
    "  As we mentioned above, a signal that only present when looking at the on-channels might be an alien signal - but if it also shows up in an off-channel we can assume it's just a boring terrestrial signal. How useful are the off-channels is a serious question for the contest, and potentially for the SETI project itself. Theoretically, the scenario that off-channels will rule out the possibility that a signal is a neelde can be very rare - so, in this case maybe its might not worth the usage of it. In the further parts of this project, we will face this question and answer it.\n",
    "  </div>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='2_3'>2.3. Data Statistics</a>\n",
    "\n",
    "#### <a id='2_3_1'>2.3.1 Needles Distribution</a>\n",
    "\n",
    "Let's create a barplot of the label frequencies in order to understand how rare is having a \"needle\" occurance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_needles = len(training_set[training_set.target==1])\n",
    "test_needles = len(testing_set[testing_set.target==1])\n",
    "\n",
    "print(f\"There are {train_needles} 'needles' in the training set, which is {(train_needles / len(training_set) * 100)} % of the set. \\n\")\n",
    "print(f\"There are {test_needles} 'needles' in the testing set, which is {(test_needles / len(testing_set) * 100)} % of the set. \\n\")\n",
    "\n",
    "sns.countplot(data=training_set, x='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at this plot, we can see that our **2nd challange** is a **very imbalanced dataset** - most of the examples are non-alien. If we will use this dataset for our predictive models without any adjustments, we might get a lot of misclassifications.\n",
    "\n",
    "> **Imbalance** means that the number of data points available for different classes is different\n",
    "\n",
    "#### <a id='2_3_2'>2.3.2 Basic Statistical Features</a>\n",
    "\n",
    "Now, let's take a look on some basic spectrogram's statistical features in order to look for outliers or hopefully find a clear difference between the alien and the non-alien ones:\n",
    "- **Mean**: The avarage pixels value in an image, provides a measure of the *overall brightness* of the image.\n",
    "- **Standard Deviation**: A measure of the dispersion of pixel values around the mean, indicating the variability in pixel values. Higher standard deviation values suggest greater contrast in the image.\n",
    "- **Min, Max**: The minimum and the maximum pixels value in an image, which will probably be 0 and 255 (black and white)\n",
    "\n",
    "\n",
    "<div style=\"border: 0.5px solid; padding: 10px; background-color: #df5e55c2; border-radius: 5px; color: #000; font-size:14px; line-height: 1.7em; display: flex; flex-direction: row;\">\n",
    "  <div style=\"width: 24px\">üì¢</div> \n",
    "  <div>\n",
    "  From now on, we will explore the training set only, with the assumption that our testing set should be pretty similar statistically.\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(spectrograms):\n",
    "    return {\n",
    "        'mean': np.mean(spectrograms),\n",
    "        'std': np.std(spectrograms),\n",
    "        'max': np.max(spectrograms),\n",
    "        'min': np.min(spectrograms)\n",
    "    }\n",
    "\n",
    "# Main\n",
    "features_list = []\n",
    "\n",
    "for _, row in training_set.iterrows():\n",
    "    file_id = row['id']\n",
    "    file_path = get_file_path(file_id, CFG.train_folder_path)\n",
    "    file = np.load(file_path)\n",
    "    spectrograms = np.vstack(file)\n",
    "\n",
    "    features = extract_features(spectrograms)\n",
    "    features['id'] = file_id\n",
    "    features['target'] = row['target']\n",
    "\n",
    "    features_list.append(features)\n",
    "\n",
    "features_df = pd.DataFrame(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After collecting these features, let's analyze them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_statistical_features(features):\n",
    "    _, axes = plt.subplots(math.ceil(len(features) / 2), 2, figsize=(10, 7))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        # sns.histplot needs convertion from float16 to float32\n",
    "        features_df[feature] = features_df[feature].astype('float32')\n",
    "        sns.histplot(features_df[features_df['target'] == 0][feature], bins=30, kde=True, color='blue', label='0', ax=axes[i])\n",
    "        sns.histplot(features_df[features_df['target'] == 1][feature], bins=30, kde=True, color='orange', label='1', ax=axes[i])\n",
    "        \n",
    "        # Set title and labels\n",
    "        axes[i].set_title(f'Distribution of {feature} by Target')\n",
    "        axes[i].set_xlabel(feature)\n",
    "        axes[i].set_ylabel('Count')\n",
    "        axes[i].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main\n",
    "plot_statistical_features(['mean', 'std', 'max', 'min'])\n",
    "\n",
    "non_inf_std_count = np.isfinite(features_df['std']).sum()\n",
    "print(f'Number of std values that are not inf: {non_inf_std_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we will conclude anything from the plots, we should handle the standard deviation (`std`) value, which appears to be `inf` for both the non-alien and alien targets. There can be a few reasons for that - the first one, is **overflow issues** during intermediate calculations, which also *match the overflow warning we can see above*. Another reason can be extreme values in the dataset (such as `inf` or `NaN`) that can significantly inflate `std`.\n",
    "\n",
    "We will try to fix the `std` calculation value using few data tweaks:\n",
    "- We will cast our data from `float16` to `float32`, that has higher precision to avoid overflow.\n",
    "- We will look for `inf` or `NaN` pixels values and replace them with finite values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_std_value(cadence_snippet):\n",
    "    cadence_snippet = cadence_snippet.astype(np.float32)\n",
    "    finite_max = np.max(cadence_snippet[np.isfinite(cadence_snippet)])\n",
    "    finite_min = np.min(cadence_snippet[np.isfinite(cadence_snippet)])\n",
    "    \n",
    "    return np.nan_to_num(cadence_snippet, nan=0.0, posinf=finite_max, neginf=finite_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = []\n",
    "\n",
    "for _, row in training_set.iterrows():\n",
    "    file_id = row['id']\n",
    "    file_path = get_file_path(file_id, CFG.train_folder_path)\n",
    "    file = np.load(file_path)\n",
    "    cadence_snippet = np.vstack(file)\n",
    "\n",
    "    features = {\n",
    "        'inf_values': np.sum(np.isinf(cadence_snippet)),\n",
    "        'nan_values': np.sum(np.isnan(cadence_snippet))\n",
    "    }\n",
    "\n",
    "    cadence_snippet = fix_std_value(cadence_snippet)\n",
    "\n",
    "    features.update(extract_features(cadence_snippet))\n",
    "    features['id'] = file_id\n",
    "    features['target'] = row['target']\n",
    "\n",
    "    features_list.append(features)\n",
    "\n",
    "features_df = pd.DataFrame(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_statistical_features(['inf_values', 'nan_values', 'mean', 'std', 'max', 'min'])\n",
    "\n",
    "non_alien_inf_values = np.sum(np.isinf(features_df[features_df['target'] == 0]['inf_values']))\n",
    "non_alien_nan_values = np.sum(np.isinf(features_df[features_df['target'] == 0]['nan_values']))\n",
    "alien_inf_values = np.sum(np.isinf(features_df[features_df['target'] == 1]['inf_values']))\n",
    "alien_nan_values = np.sum(np.isinf(features_df[features_df['target'] == 1]['nan_values']))\n",
    "\n",
    "print(f'Number of inf values in target 0: {non_alien_inf_values}, in target 1: {alien_inf_values}')\n",
    "print(f'Number of nan values in target 0: {non_alien_nan_values}, in target 1: {alien_nan_values}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Looks like our `std` is fine now. As we can see there are no `inf` of `NaN` pixels values, and there is no overflow warning anymore. We can infer that he `std` fixed by the `float32` casting. There are few more things we can infer as well:\n",
    "- The aliens and non-aliens samples have a pretty similar graphs trends in all of our checked statistical features. Hence, non of these features can potentially serve as discriminative factor.\n",
    "- The `std` is pretty small - which means the variance of our each cadence snippet is very small. **small data variance** will consider as our **3rd challange** for a few reasons, like - the challange of preserving essential features while preforming dimensionality reduction or resizing.\n",
    "\n",
    "\n",
    "Now, we will try to look at the outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_outliers(lowest_df, highest_df, target_0_amount, target_1_amount, feature):\n",
    "    figsize=(14, 4)\n",
    "    lowest_ids = get_samples_id(lowest_df, target_0_amount, target_1_amount)\n",
    "    print(f'Lowest {feature} candece snippets:')\n",
    "    [print(lowest_df.loc[lowest_df['id'] == id, feature].values[0]) for id in lowest_ids]\n",
    "    \n",
    "    cadence_snippets = [np.load(get_file_path(id, CFG.train_folder_path)) for id in lowest_ids]\n",
    "    plot_multiple_cadence_snippets(cadence_snippets, figsize=figsize)\n",
    "\n",
    "    highest_ids = get_samples_id(highest_df, target_0_amount, target_1_amount)\n",
    "    print(f'Highest {feature} candece snippets:')\n",
    "    [print(highest_df.loc[highest_df['id'] == id, feature].values[0]) for id in highest_ids]\n",
    "\n",
    "    cadence_snippets = [np.load(get_file_path(id, CFG.train_folder_path)) for id in highest_ids]\n",
    "    plot_multiple_cadence_snippets(cadence_snippets, figsize=figsize)\n",
    "\n",
    "# Main\n",
    "lowest, medium, highest = get_samples_by_threshold(features_df, 'std', 5, 95)\n",
    "display_outliers(lowest, highest, 2, 1, 'std')\n",
    "\n",
    "lowest, medium, highest = get_samples_by_threshold(features_df, 'mean', 5, 95)\n",
    "display_outliers(lowest, highest, 2, 1, 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the `std` and `mean` values has a very narrow range of values. We can also see, by looking at the images - that the outliers of these two features are just fine to work with, and there is **no outliers that needs to be removed at this point**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='2_4'>2.4 Noise Analyzing</a>\n",
    "As we saw in the Data Visualizing section and in the Standard Devition calculation, our data is not varying much and it also full of noises. Noise Analyzing will help us understand better our dataset for few reasons:\n",
    "- We can use Noise Analysis to determine if this lack of variation is due to actual data properties or if it's caused by noise. \n",
    "- We can try find noise indicators which are also discriminative factors between alien and non-alien signal\n",
    "- We will use this analyzing for removing some of the noises in the next sections.\n",
    "\n",
    "#### <a id='2_4_1'>2.4.1 Gaussian Noise</a>\n",
    "`Gaussian Noise`, also known as normal noise, is a fundamental concept in signal processing and statistics. It is called *Gaussian* because its probability density function (*PDF*) follows a Gaussian (normal) distribution. By estimating the standard deviation of the Gaussian noise in the images, we can gain insights into the level of noise present and its impact on the image quality.\n",
    "\n",
    "Let's analyze the Gaussian noise std using `estimate_sigma ` function, which based on **Wavelet Decomposition** to estimate the noise level in an image:\n",
    "> **Wavelet Decomposition** - Wavelets are mathematical functions that can be used to divide a function or a continuous-time signal into different frequency components, this helps isolate the high-frequency noise from the low-frequency signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_noise_list = []\n",
    "\n",
    "for _, row in training_set.iterrows():\n",
    "    file_id = row['id']\n",
    "    file_path = get_file_path(file_id, CFG.train_folder_path)\n",
    "    file = np.load(file_path)\n",
    "\n",
    "    spectrograms = np.vstack(file)\n",
    "    spectrograms = spectrograms.astype(np.float32)\n",
    "\n",
    "    gaussian_noise = {\n",
    "        'noise': estimate_sigma(spectrograms, channel_axis=None, average_sigmas=True)\n",
    "    }\n",
    "    gaussian_noise['id'] = file_id\n",
    "    gaussian_noise['target'] = row['target']\n",
    "\n",
    "    gaussian_noise_list.append(gaussian_noise)\n",
    "\n",
    "gaussian_noise_df = pd.DataFrame(gaussian_noise_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "# Plot distribution of Gaussian Noise by target\n",
    "sns.histplot(gaussian_noise_df[gaussian_noise_df['target'] == 0]['noise'], bins=30, kde=True, color='blue', label='Target 0')\n",
    "sns.histplot(gaussian_noise_df[gaussian_noise_df['target'] == 1]['noise'], bins=30, kde=True, color='orange', label='Target 1')\n",
    "plt.title('Distribution of Gaussian Noise by Target')\n",
    "plt.xlabel('Estimated Noise Level')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like most of our images has a low rate of Gaussian Noise, which generally indicates that most of the data is relatively \"clean\". In order to understand what clean means in our type of data, let's take a look over some outliers and some images that are just in the median Gaussian distribution.\n",
    "\n",
    "We will plot 3 non-alien signals and then 3 alien signals for: lowest noise images, median noise images and highest noise cadence snippets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_aliens_amount = training_set['target'].value_counts().get(0,0)\n",
    "aliens_amount = training_set['target'].value_counts().get(1,0)\n",
    "\n",
    "def display_noise_images(noise_images_df, title):\n",
    "    target_counts = noise_images_df['target'].value_counts()\n",
    "    non_aliens_ratio = (target_counts.get(0, 0) / non_aliens_amount) * 100\n",
    "    aliens_ratio = (target_counts.get(1, 0) / aliens_amount) * 100\n",
    "    images_id = get_samples_id(noise_images_df, 3, 3)\n",
    "\n",
    "    print(title)\n",
    "    print(f'Target 0: {non_aliens_ratio}%, Target 1: {aliens_ratio}%')\n",
    "\n",
    "    cadences_snippet = [np.load(get_file_path(id, CFG.train_folder_path)) for id in images_id]\n",
    "    plot_multiple_cadence_snippets(cadences_snippet, figsize=(18, 12))\n",
    "\n",
    "# Main\n",
    "lowest_noise_images, median_noise_images, highest_noise_images = get_samples_by_threshold(gaussian_noise_df, 'noise', 10, 90)\n",
    "\n",
    "display_noise_images(lowest_noise_images, '\\nLowest Gaussian noise images:')\n",
    "display_noise_images(median_noise_images, '\\nMedian Gaussian noise images:')\n",
    "display_noise_images(highest_noise_images, '\\nHighest Gaussian noise images:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting images! We knew that the less noise we have - the cleaner the image is. But, we can now sense and understand how the noise affect image clearity.\n",
    "\n",
    "As we can see, The lowest noise images are very clear and clean, and some of its needels are pretty noticable, but yet - some of them doesnt. The median noise images are less clear and so does the needels. The highest noise images has a very bad quality and it like the needels finding is the hardest, \n",
    "\n",
    "<div style=\"border: 0.5px solid; padding: 10px; background-color: #df5e55c2; border-radius: 5px; color: #000; font-size:14px; line-height: 1.7em; display: flex; flex-direction: row;\">\n",
    "  <div style=\"width: 24px\">üì¢</div> \n",
    "  <div>\n",
    "  If we will see in the training section that the prediction of this type of images are less accurate, we will consider to remove them from our dataset.\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "Although it looks like the mean noise of our images is pretty low, there are still a lot of static frequencies that create \"noise\" and makes the needels harder to find. Let's explore them:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='2_4_2'>2.4.2 Frequency Domain Analysis</a>\n",
    "\n",
    "`Frequency Domain Analysis` is a powerful technique used in image processing to examine the frequency components of an image. This analysis transforms an image from the spatial domain (where pixel values are analyzed) to the frequency domain, where the image is represented by its frequency components.\n",
    "\n",
    "The core of `Frequency Domain Analysis` is the `Fourier Transform`, which decomposes an image into its constituent frequencies. So, we need to start with understanding `Fourier Transform` meaning:\n",
    "\n",
    "In the picture below, we can see the **Time Domain** representation of a audio signal, which shows the \"loudness\" (amplitude) of sounds wave changing with time. To better understand an audio signal, it is necessary to transform it into the **Frequency Domain** representation. This representation of a signal tells us what different frequencies are present in the signal.<br></br>\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*e-_z80BnbHWyFTfRLblJ_w.gif\" width=\"400\"><br></br>\n",
    "`Fourier Transform` is a mathematical concept that can *decompose a signal into its constituent frequencies*. In its 2D plot output, the x-axis represent the signal frequencies and the y-axis represent their magnitudes (amplitude size). There is also `Inverse Fourier Transform` concept, which is just the opposite of the Fourier Transform.<br></br>\n",
    " For a better understanding of Fourier Transform output - let's create two simple sine waves, with two different frequencies:  *amplitude = 1 and frequency = 3* and *amplitude = 2 and frequency = 11*.\n",
    " Now, we can combine them into a single signal, that will look like that - <br></br>\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*WBldOpArJgDXIFs5g_JydA.png\" width=\"400\"><br></br>\n",
    "The output of Fourier Transform will show two spikes  for the two frequencies and their magnitudes <br></br>\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*aIyR6XoUYGJp0_3Ug6iEyA.png\" width=\"400\"><br></br>\n",
    "For more information, you can read the article - [understand autio fft](https://towardsdatascience.com/understanding-audio-data-fourier-transform-fft-spectrogram-and-speech-recognition-a4072d228520)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having said that, we can use `Fourier Transform` to analyze frequencies of each spectrogram, it will include the following steps:\n",
    "1. **Compute FFT for each image**: by using `np.fft.fft2` method\n",
    "2. **Center frequencies**: move the zero frequency component to the center, by using `np.fft.fftshift`\n",
    "3. **Extract magnitude spectrum for each image**: calculate the magnitude of the frequency components in a logarithmic scale by using `np.log1p`.\n",
    "4. **Extract low and high frequencies for each image**: by using statistical thresholds, when can extract from a magnitude its low and high frequencies. \n",
    ">   - **Low Frequencies**: correspond to slower oscillations or longer wavelengths in the signal. Often, the fundamental frequencies of sounds or   signals fall in the low-frequency range and they have higher amplitude than highers ones.\n",
    "located in the center of the magnitude spectrum and represent smooth variations and general trends in the image.\n",
    ">   - **High Frequencies**:  correspond to faster oscillations or shorter wavelengths in the signal. In a spectrogram, these are represented by components that change rapidly over time.\n",
    "\n",
    "Sounds like the basic \"noising\" signals - the vertical and the horizontal ones, will probably consider as **Low Frequencies**, and the needles will probably consider as **High Frequency**.\n",
    "\n",
    "Let's start with extracting these features for each cadence snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_magnitude_spectrum(spectrogram):\n",
    "    spectrogram = spectrogram.astype(np.float32)\n",
    "    spectrogram_frequencies_domain = np.fft.fft2(spectrogram)\n",
    "    spectrogram_frequencies_domain = np.fft.fftshift(spectrogram_frequencies_domain)\n",
    "    \n",
    "    magnitude_spectrum = np.abs(spectrogram_frequencies_domain)\n",
    "    # Apply logarithmic scaling and normalization for better visualization\n",
    "    magnitude_spectrum_log = np.log1p(magnitude_spectrum)\n",
    "    return (magnitude_spectrum_log - np.min(magnitude_spectrum_log)) / (np.max(magnitude_spectrum_log) - np.min(magnitude_spectrum_log))\n",
    "\n",
    "def extract_cadence_frequency_features(cadence_snippet):\n",
    "    magnitude_spectrums = []\n",
    "    for spectrogram in cadence_snippet:\n",
    "        magnitude_spectrums.append(extract_magnitude_spectrum(spectrogram))\n",
    "\n",
    "    threshold = np.mean(magnitude_spectrums) + 2 * np.std(magnitude_spectrums)\n",
    "    low_frequencies = np.sum(magnitude_spectrums <= threshold)\n",
    "    high_frequencies = np.sum(magnitude_spectrums > threshold)\n",
    "\n",
    "    return magnitude_spectrums, low_frequencies, high_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the code above for plotting these features for few samples from each Gaussian noise group (low, med and high):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cadence_snippet_with_magnitudes(cadence_snippet, title, figsize=(10,4)):\n",
    "    _, axes = plt.subplots(nrows=6, ncols=2, figsize=figsize)\n",
    "    axes[0, 0].set_title('Original spectrogram', fontsize=10)\n",
    "    axes[0, 1].set_title('Magnitude Spectrogram', fontsize=10)\n",
    "    magnitude_spectrums, low_frequencies, high_frequencies = extract_cadence_frequency_features(cadence_snippet)\n",
    "    \n",
    "    print(title)\n",
    "    print(f'Number of low frequencies: {low_frequencies}')\n",
    "    print(f'Number of high frequencies: {high_frequencies}')\n",
    "\n",
    "    for i in range(6):\n",
    "        spectrogram = cadence_snippet[i].astype('float16')\n",
    "        magnitude_spectrum = magnitude_spectrums[i].astype('float16')\n",
    "        # For zoom-in\n",
    "        center = np.array(magnitude_spectrum.shape) // 2\n",
    "        crop_size = np.array(magnitude_spectrum.shape) // 2\n",
    "        start = center - crop_size // 2\n",
    "        end = center + crop_size // 2\n",
    "        # For spectrogram channel text box\n",
    "        channel_text = 'on' if i % 2 == 0 else 'off'\n",
    "        channel_box = dict(facecolor='white', edgecolor='none', boxstyle='square,pad=0.3')\n",
    "\n",
    "        ax_spectrogram = axes[i, 0]\n",
    "        ax_spectrogram.imshow(spectrogram, aspect='auto', cmap='gray')\n",
    "        ax_spectrogram.text(10, 90, channel_text, color='black', fontsize=8, va='center', ha='center', bbox=channel_box)\n",
    "        ax_spectrogram.axis('off')\n",
    "        \n",
    "        ax_magnitude = axes[i, 1]\n",
    "        ax_magnitude.imshow(magnitude_spectrum[start[0]:end[0], start[1]:end[1]], aspect='auto', cmap='inferno')\n",
    "        ax_magnitude.text(7, 45, channel_text, color='black', fontsize=8, va='center', ha='center', bbox=channel_box)\n",
    "        ax_magnitude.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main\n",
    "lowest_noise_image_0 = lowest_noise_images[lowest_noise_images['target'] == 0].head(1)['id'].iloc[0]\n",
    "lowest_noise_image_1 = lowest_noise_images[lowest_noise_images['target'] == 1].head(1)['id'].iloc[0]\n",
    "plot_cadence_snippet_with_magnitudes(np.load(get_file_path(lowest_noise_image_0, CFG.train_folder_path)), 'Low noise negative sample:')\n",
    "plot_cadence_snippet_with_magnitudes(np.load(get_file_path(lowest_noise_image_1, CFG.train_folder_path)), 'Low noise positive sample:')\n",
    "\n",
    "median_noise_image_0 = median_noise_images[median_noise_images['target'] == 0].head(1)['id'].iloc[0]\n",
    "median_noise_image_1 = median_noise_images[median_noise_images['target'] == 1].head(1)['id'].iloc[0]\n",
    "plot_cadence_snippet_with_magnitudes(np.load(get_file_path(median_noise_image_0, CFG.train_folder_path)), 'Med noise negative sample:')\n",
    "plot_cadence_snippet_with_magnitudes(np.load(get_file_path(median_noise_image_1, CFG.train_folder_path)), 'Med noise positive sample:')\n",
    "\n",
    "highest_noise_image_0 = highest_noise_images[highest_noise_images['target'] == 0].head(1)['id'].iloc[0]\n",
    "highest_noise_image_1 = highest_noise_images[highest_noise_images['target'] == 1].head(1)['id'].iloc[0]\n",
    "plot_cadence_snippet_with_magnitudes(np.load(get_file_path(highest_noise_image_0, CFG.train_folder_path)), 'High noise negative sample:')\n",
    "plot_cadence_snippet_with_magnitudes(np.load(get_file_path(highest_noise_image_1, CFG.train_folder_path)), 'High noise positive sample:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! We plotted for each one of our chosen data samples their magnitude spectrums and their high and low frequencies. As expected, from our plotted data samples it looks like the cleaner the image is - the more high frequencies we found.\n",
    "\n",
    "Now, let's calculate these features on our entire training set so we will try to conculde some interesting points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_noise_level(cadence_id):\n",
    "    if cadence_id in lowest_noise_images['id'].values:\n",
    "        return 'low'\n",
    "    elif cadence_id in median_noise_images['id'].values:\n",
    "        return 'medium'\n",
    "    elif cadence_id in highest_noise_images['id'].values:\n",
    "        return 'high'\n",
    "    return 'medium'\n",
    "\n",
    "# Main    \n",
    "frequencies_list = []\n",
    "\n",
    "for _, row in training_set.iterrows():\n",
    "    file_id = row['id']\n",
    "    file_path = get_file_path(file_id, CFG.train_folder_path)\n",
    "    cadence_snippet = np.load(file_path)\n",
    "\n",
    "    _, low_frequencies, high_frequencies = extract_cadence_frequency_features(cadence_snippet)\n",
    "\n",
    "    frequencies = {\n",
    "        'low_frequencies': low_frequencies,\n",
    "        'high_frequencies': high_frequencies,\n",
    "        'noise_level': determine_noise_level(file_id),\n",
    "        'id': file_id,\n",
    "        'target': row['target']\n",
    "    }\n",
    "\n",
    "    frequencies_list.append(frequencies)\n",
    "\n",
    "frequencies_df = pd.DataFrame(frequencies_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for index, noise_level in enumerate(['low', 'medium', 'high']):\n",
    "    noise_df = frequencies_df[frequencies_df['noise_level'] == noise_level]\n",
    "        \n",
    "    ax_low_frequencies = axes[index * 2] \n",
    "    sns.histplot(data=noise_df, x='low_frequencies', hue='target', kde=True, ax=ax_low_frequencies)\n",
    "    ax_low_frequencies.set_title(f'{noise_level.capitalize()} Noise - Low Frequencies by Target')\n",
    "    ax_low_frequencies.set_xlabel('Low Frequency')\n",
    "    ax_low_frequencies.set_ylabel('Count')\n",
    "        \n",
    "    ax_high_frequencies = axes[index * 2 + 1]  \n",
    "    sns.histplot(data=noise_df, x='high_frequencies', hue='target', kde=True, ax=ax_high_frequencies)\n",
    "    ax_high_frequencies.set_title(f'{noise_level.capitalize()} Noise - High Frequencies by Target')\n",
    "    ax_high_frequencies.set_xlabel('High Frequency')\n",
    "    ax_high_frequencies.set_ylabel('Count')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! It looks like the **Low Frequencies** amount is pretty much the same between the different noise level images, the main different is the amount of the **High Frequencies** - The images with the lowest noise has 12,000-18,000 high frequencies in average, the medium noise images has 5,000-15,000 high frequencies in average and the images with the highest noise has 1,000-3,000 high frequencies in average. We don't know yet if the small amount of high frequencies is due to bad images quality or another reason. Anyway, as we already said: **in the further sections - we might decide to consider some of the highest noise samples as outliers and remove them from our training set**.\n",
    "\n",
    "Let's take a look over a `correlation matrix` as well, to examine if there is a correlation between freqency type to noise level:\n",
    "> **Correlation Matrix**: Helps understand the relationships between the variables in a dataset based on their correlation coefficients. The diagonal values in the correlation matrix will always be 1, as a variable is perfectly correlated with itself - But, the off-diagonal elements show the correlation between different pairs of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level_mapping = {'low': 0, 'medium': 1, 'high': 2}\n",
    "frequencies_df['noise_level_numeric'] = frequencies_df['noise_level'].map(noise_level_mapping)\n",
    "\n",
    "correlation_matrix = frequencies_df[['low_frequencies', 'high_frequencies', 'noise_level_numeric']].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
